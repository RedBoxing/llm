{
  // Use IntelliSense to learn about possible attributes.
  // Hover to view descriptions of existing attributes.
  // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
  "version": "0.2.0",
  "configurations": [
    {
      "type": "lldb",
      "request": "launch",
      "name": "Debug BLOOM Inference",
      "cargo": {
        "args": ["build", "--example=inference", "--package=llm"],
        "filter": {
          "name": "inference",
          "kind": "example"
        }
      },
      "args": ["bloom", "${env:HOME}/.ggml-models/bloom-7b.bin"],
      "cwd": "${workspaceFolder}"
    },
    {
      "type": "lldb",
      "request": "launch",
      "name": "Debug GPT-2 Inference",
      "cargo": {
        "args": ["build", "--example=inference", "--package=llm"],
        "filter": {
          "name": "inference",
          "kind": "example"
        }
      },
      "args": ["gpt2", "${env:HOME}/.ggml-models/cerebras-gpt-13b.bin"],
      "cwd": "${workspaceFolder}"
    },
    {
      "type": "lldb",
      "request": "launch",
      "name": "Debug GPT-J Inference",
      "cargo": {
        "args": [
          "build",
          "--example=inference",
          "--package=llm"
        ],
        "filter": {
          "name": "inference",
          "kind": "example"
        }
      },
      "args": ["gptj", "${env:HOME}/.ggml-models/gpt-j-6b.bin"],
      "cwd": "${workspaceFolder}"
    },
    {
      "type": "lldb",
      "request": "launch",
      "name": "Debug LLaMA Inference",
      "cargo": {
        "args": ["build", "--example=inference", "--package=llm"],
        "filter": {
          "name": "inference",
          "kind": "example"
        }
      },
      "args": ["llama", "${env:HOME}/.ggml-models/llama-13b-q5_1.bin", "${env:HOME}/llama-dl/tokenizer.json"],
      "cwd": "${workspaceFolder}"
    },
    {
      "type": "lldb",
      "request": "launch",
      "name": "Debug GPT-NeoX Inference",
      "cargo": {
        "args": ["build", "--example=inference", "--package=llm"],
        "filter": {
          "name": "inference",
          "kind": "example"
        }
      },
      "args": ["gptneox", "${env:HOME}/.ggml-models/stablelm-base-alpha-3b.bin"],
      "cwd": "${workspaceFolder}"
    },
    {
      "type": "lldb",
      "request": "launch",
      "name": "Debug RedPajama Inference",
      "cargo": {
        "args": ["build", "--example=inference", "--package=llm"],
        "filter": {
          "name": "inference",
          "kind": "example"
        }
      },
      "args": ["redpajama", "${env:HOME}/.ggml-models/redpajama-incite-7b.bin"],
      "cwd": "${workspaceFolder}"
    },
    {
      "type": "lldb",
      "request": "launch",
      "name": "Debug Vicuna Chat",
      "cargo": {
        "args": ["build", "--example=vicuna-chat", "--package=llm"],
        "filter": {
          "name": "vicuna-chat",
          "kind": "example"
        }
      },
      "args": ["llama", "${env:HOME}/.ggml-models/wizardlm-7b.bin"],
      "cwd": "${workspaceFolder}"
    },
    {
      "type": "lldb",
      "request": "launch",
      "name": "Debug RWKV Inference",
      "cargo": {
        "args": ["build", "--example=inference", "--package=llm"],
        "filter": {
          "name": "inference",
          "kind": "example"
        }
      },
      "args": ["rwkv", "${env:HOME}/.ggml-models/rwkv-raven-14b-v9-q4_1.bin", "${env:HOME}/RWKV/rwkv.cpp/rwkv/20B_tokenizer.json"],
      "cwd": "${workspaceFolder}"
    }
  ]
}
